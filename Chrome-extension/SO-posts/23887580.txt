<p>I think you have forgotten to call the JavaSparkContext stop() method at the end. Would the following also give you error?</p>

<pre><code>public class SimpleApp{ 
public static void main(String[] args) { 
        String logFile = "/usr/Java/spark-0.9.0/README.md"; 
        JavaSparkContext sc = new JavaSparkContext("local", "Simple App","/usr/Java/spark-0.9.0",new String[] { "target/testspark-0.0.1-SNAPSHOT.jar" }); 
        JavaRDD&lt;String&gt; logData = sc.textFile(logFile).cache(); 
        long numAs = logData.filter(new Function&lt;String, Boolean&gt;() { 
                public Boolean call(String s) { 
                        return s.contains("a"); 
                } 
        }).count(); 

        long numBs = logData.filter(new Function&lt;String, Boolean&gt;() { 
                public Boolean call(String s) { 
                        return s.contains("b"); 
                } 
        }).count(); 

        System.out.println("Lines with a: " + numAs + ", lines with b: " + numBs);
        sc.stop();
  }
}
</code></pre>

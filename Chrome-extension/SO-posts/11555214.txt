<p>You can do this.</p>

<p>Use <code>public void schedule(WebURL url)</code> to add URLs to the crawler frontier which is a member of the <code>Frontier.java</code> class. But for this you need to have your url of type <code>WebURL</code>. If you want to make a <code>WebURL</code> out of your string. Please have a look at the <code>addSeed()</code> (below code) which is in the <code>CrawlController.java</code> class to see how it has converted the string (url) into a WebURL.</p>

<p>Also use the existing frontier instance.</p>

<p>Hope this helps..</p>

<pre><code>public void addSeed(String pageUrl, int docId) {
        String canonicalUrl = URLCanonicalizer.getCanonicalURL(pageUrl);
        if (canonicalUrl == null) {
            logger.error("Invalid seed URL: " + pageUrl);
            return;
        }
        if (docId &lt; 0) {
            docId = docIdServer.getDocId(canonicalUrl);
            if (docId &gt; 0) {
                // This URL is already seen.
                return;
            }
            docId = docIdServer.getNewDocID(canonicalUrl);
        } else {
            try {
                docIdServer.addUrlAndDocId(canonicalUrl, docId);
            } catch (Exception e) {
                logger.error("Could not add seed: " + e.getMessage());
            }
        }

        WebURL webUrl = new WebURL();
        webUrl.setURL(canonicalUrl);
        webUrl.setDocid(docId);
        webUrl.setDepth((short) 0);
        if (!robotstxtServer.allows(webUrl)) {
            logger.info("Robots.txt does not allow this seed: " + pageUrl);
        } else {
            frontier.schedule(webUrl); //method that adds URL to the frontier at run time
        }
    } 
</code></pre>

<p>You need to use <code>JTomatoSoup</code> Its uses is:  </p>

<blockquote>
  <p>scrape and parse HTML from a URL, file, or string<br>
      find and extract data, using DOM traversal or CSS selectors<br>
      manipulate the HTML elements, attributes, and text<br>
      clean user-submitted content against a safe white-list, to prevent XSS attacks<br>
      output tidy HTML  </p>
</blockquote>

<p>The site also has a simple get started example but here is an <strong>SSCCE</strong> from Mykong:  </p>

<pre><code>import java.io.IOException;

import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class HTMLParserExample1 {

  public static void main(String[] args) {

    Document doc;
    try {

        // need http protocol
        doc = Jsoup.connect("http://google.com").get();

        // get page title
        String title = doc.title();
        System.out.println("title : " + title);

        // get all links
        Elements links = doc.select("a[href]");
        for (Element link : links) {

            // get the value from href attribute
            System.out.println("\nlink : " + link.attr("href"));
            System.out.println("text : " + link.text());

        }

    } catch (IOException e) {
        e.printStackTrace();
    }

  }

}  
</code></pre>

<p>Website: <a href="http://jsoup.org/" rel="nofollow">http://jsoup.org/</a></p>

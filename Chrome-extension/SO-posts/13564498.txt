<p><H2>1) Few words about Levenshtein distance algorithm improvement</H2></p>

<p><strong>Recursive implementation of Levenshteins distance has exponential complexity</strong>.</p>

<p>I'd suggest you to use <strong>memoization technique</strong> and implement Levenshtein distance without recursion, and reduce complexity to <code>O(N^2)</code>(needs <code>O(N^2)</code> memory)</p>

<pre><code>public static int levenshteinDistance( String s1, String s2 ) {
    return dist( s1.toCharArray(), s2.toCharArray() );
}

public static int dist( char[] s1, char[] s2 ) {

    // distance matrix - to memoize distances between substrings
    // needed to avoid recursion
    int[][] d = new int[ s1.length + 1 ][ s2.length + 1 ];

    // d[i][j] - would contain distance between such substrings:
    // s1.subString(0, i) and s2.subString(0, j)

    for( int i = 0; i &lt; s1.length + 1; i++ ) {
        d[ i ][ 0 ] = i;
    }

    for(int j = 0; j &lt; s2.length + 1; j++) {
        d[ 0 ][ j ] = j;
    }

    for( int i = 1; i &lt; s1.length + 1; i++ ) {
        for( int j = 1; j &lt; s2.length + 1; j++ ) {
            int d1 = d[ i - 1 ][ j ] + 1;
            int d2 = d[ i ][ j - 1 ] + 1;
            int d3 = d[ i - 1 ][ j - 1 ];
            if ( s1[ i - 1 ] != s2[ j - 1 ] ) {
                d3 += 1;
            }
            d[ i ][ j ] = Math.min( Math.min( d1, d2 ), d3 );
        }
    }
    return d[ s1.length ][ s2.length ];
}
</code></pre>

<p>Or, even better - you may notice, that for each cell in distance matrix - you're need only information about previous line, so <strong>you can reduce memory needs to <code>O(N)</code></strong>:</p>

<pre><code>public static int dist( char[] s1, char[] s2 ) {

    // memoize only previous line of distance matrix     
    int[] prev = new int[ s2.length + 1 ];

    for( int j = 0; j &lt; s2.length + 1; j++ ) {
        prev[ j ] = j;
    }

    for( int i = 1; i &lt; s1.length + 1; i++ ) {

        // calculate current line of distance matrix     
        int[] curr = new int[ s2.length + 1 ];
        curr[0] = i;

        for( int j = 1; j &lt; s2.length + 1; j++ ) {
            int d1 = prev[ j ] + 1;
            int d2 = curr[ j - 1 ] + 1;
            int d3 = prev[ j - 1 ];
            if ( s1[ i - 1 ] != s2[ j - 1 ] ) {
                d3 += 1;
            }
            curr[ j ] = Math.min( Math.min( d1, d2 ), d3 );
        }

        // define current line of distance matrix as previous     
        prev = curr;
    }
    return prev[ s2.length ];
}
</code></pre>

<p><H2>2) Few words about autocomplete</H2></p>

<p>Levenshtein's distance is perferred only if you need to find exact matches.
<br/>
<br/>
But what if your keyword would be <strong><code>apple</code></strong> and user typed <strong><code>green apples</code></strong>? Levenshteins distance between query and keyword would be large (<strong>7 points</strong>). And Levensteins distance between <strong><code>apple</code></strong> and <strong><code>bcdfghk</code></strong> (dumb string) would be <strong>7 points</strong> too!
<br/>
<br/>
I'd suggest you to use <strong>full-text search engine</strong> (e.g. <a href="http://lucene.apache.org/">Lucene</a>). The trick is - that you have to use <strong><a href="http://en.wikipedia.org/wiki/N-gram">n-gram</a></strong> model to represent each keyword.
<br/>
<br/>
In few words:
<br/>
<strong>1)</strong> you have to represent each keyword as document, which contains n-grams: <code>apple -&gt; [ap, pp, pl, le]</code>.
<br/>
<br/>
<strong>2)</strong> after transforming each keyword to set of n-grams - you have to <strong>index each keyword-document</strong> by n-gram in your search engine. You'll have to create index like this:</p>

<pre><code>...
ap -&gt; apple, map, happy ...
pp -&gt; apple ...
pl -&gt; apple, place ...
...
</code></pre>

<p><strong>3)</strong> So you have n-gram index. <strong>When you're get query - you have to split it into n-grams</strong>. Aftre this - you'll have set of users query n-grams. And all you need - is to match most similar documents from your search engine. In draft approach it would be enough.
<br/>
<br/>
<strong>4)</strong> For better suggest - you may rank results of search-engine by Levenshtein distance.
<br/>
<br/></p>

<p><strong>P.S.</strong> I'd suggest you to look through the book <strong><a href="http://rads.stackoverflow.com/amzn/click/0521865719">"Introduction to information retrieval"</a></strong>.</p>

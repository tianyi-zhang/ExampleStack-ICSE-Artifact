<p>Right after a long fight with Android API I have managed to get this working.</p>

<p>There were two issues that caused the green/purple output;</p>

<p><strong>Loss of data:</strong> the generated YUV frame was larger than the original preview frame at the same resolution, so the data being passed down to the native code was missing around 30% of its image data.</p>

<p><strong>Wrong resolution:</strong> the native code required the resolution of the preview frame and not the camera.</p>

<p>Below is a working solution for anyone who wishes to add a static frame;</p>

<p>so updated code:</p>

<pre><code>@Override
public byte[] getPreviewFrameData(int width, int height) {
    if (mPreviewFrameData == null) {
        loadPreviewFrame(width, height);
    }

    return mPreviewFrameData;
}

private void loadPreviewFrame(int width, int height) {
    try {
        Bitmap previewImage = BitmapFactory.decodeResource(mContext.getResources(), R.drawable.frame);
        Bitmap resizedPreviewImage = Bitmap.createScaledBitmap(previewImage, width, height, false);

        BitmapConverter bitmapConverter = new BitmapConverter();
        mPreviewFrameData = bitmapConverter.convertToNV21(resizedPreviewImage);
    } catch (Exception e) {
        Log.e("DisabledCameraFrameProvider", "Failed to loadPreviewFrame");
    }
}

class BitmapConverter {
    byte [] convertToNV21(Bitmap bitmap) {
        int inputWidth = bitmap.getWidth();
        int inputHeight = bitmap.getHeight();

        int [] argb = new int[inputWidth * inputHeight];

        bitmap.getPixels(argb, 0, inputWidth, 0, 0, inputWidth, inputHeight);

        byte [] yuv = new byte[inputWidth*inputHeight*3/2];
        encodeYUV420SP(yuv, argb, inputWidth, inputHeight);

        bitmap.recycle();

        return yuv;
    }

    void encodeYUV420SP(byte[] yuv420sp, int[] argb, int width, int height) {
        final int frameSize = width * height;

        int yIndex = 0;
        int uvIndex = frameSize;

        int R, G, B, Y, U, V;
        int index = 0;
        for (int j = 0; j &lt; height; j++) {
            for (int i = 0; i &lt; width; i++) {
                R = (argb[index] &amp; 0xff0000) &gt;&gt; 16;
                G = (argb[index] &amp; 0xff00) &gt;&gt; 8;
                B = (argb[index] &amp; 0xff);

                Y = ( (  66 * R + 129 * G +  25 * B + 128) &gt;&gt; 8) +  16;
                U = ( ( -38 * R -  74 * G + 112 * B + 128) &gt;&gt; 8) + 128;
                V = ( ( 112 * R -  94 * G -  18 * B + 128) &gt;&gt; 8) + 128;

                yuv420sp[yIndex++] = (byte) ((Y &lt; 0) ? 0 : ((Y &gt; 255) ? 255 : Y));
                if (j % 2 == 0 &amp;&amp; index % 2 == 0) {
                    yuv420sp[uvIndex++] = (byte)((V&lt;0) ? 0 : ((V &gt; 255) ? 255 : V));
                    yuv420sp[uvIndex++] = (byte)((U&lt;0) ? 0 : ((U &gt; 255) ? 255 : U));
                }

                index ++;
            }
        }
    }
}
</code></pre>

<p>Then finally in your callback;</p>

<pre><code>public void onPreviewFrame(byte[] data, Camera camera) {

     byte[] bytes = data;

     if (!mProvider.isVideoEnabled()) {
         Camera.Size previewSize = camera.getParameters().getPreviewSize();
         bytes = mProvider.getPreviewFrameData(previewSize.width, previewSize.height);
     }

     ProvideCameraFrame(bytes, bytes.length, context);
}
</code></pre>

<p>The key was to scale the image to the camera preview size and convert the image to YUV colour space.</p>
